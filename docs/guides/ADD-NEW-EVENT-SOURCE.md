# æ–°å¢è³½äº‹ä¾†æºæµç¨‹

> å®Œæ•´çš„è³½äº‹ä¾†æºæ–°å¢æŒ‡å—ï¼Œå¾é ­åˆ°å°¾ä¸€æ­¥æ­¥æ•™ä½ å¦‚ä½•æ–°å¢æ–°çš„è³½äº‹çˆ¬èŸ²

---

## ğŸ“‹ ç›®éŒ„

1. [æ¦‚è¦½](#æ¦‚è¦½)
2. [å‰ç½®éœ€æ±‚](#å‰ç½®éœ€æ±‚)
3. [å®Œæ•´æµç¨‹](#å®Œæ•´æµç¨‹)
4. [æ¸¬è©¦æª¢æŸ¥æ¸…å–®](#æ¸¬è©¦æª¢æŸ¥æ¸…å–®)
5. [ç¯„ä¾‹ï¼šæ–°å¢ç±ƒçƒè³½äº‹](#ç¯„ä¾‹æ–°å¢ç±ƒçƒè³½äº‹)
6. [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)

---

## æ¦‚è¦½

### ç‚ºä»€éº¼å®¹æ˜“æ“´å……ï¼Ÿ

æœ¬å°ˆæ¡ˆæ¡ç”¨**ä½è€¦åˆè¨­è¨ˆ**ï¼Œæ–°å¢è³½äº‹ä¾†æºåªéœ€ï¼š

1. âœ… å»ºç«‹ä¸€å€‹æ–°çš„ scraper package
2. âœ… å¯¦ä½œçˆ¬èŸ²é‚è¼¯ï¼ˆç¹¼æ‰¿ `BaseScraper`ï¼‰
3. âœ… è¨­å®šæ’ç¨‹èˆ‡åˆ†é¡
4. âŒ **ä¸éœ€è¦ä¿®æ”¹**æ ¸å¿ƒæ¡†æ¶ï¼ˆ`scraper-core`ã€`json-manager`ã€`ics-generator`ï¼‰
5. âŒ **ä¸éœ€è¦ä¿®æ”¹**å‰ç«¯æ ¸å¿ƒé‚è¼¯

### æ–°å¢è³½äº‹æ¶æ§‹åœ–

```
1. å»ºç«‹ Package
   packages/scraper-{event}/

2. å¯¦ä½œ Scraperï¼ˆTDDï¼‰
   ç¹¼æ‰¿ BaseScraper
   å¯¦ä½œ scrape() èˆ‡ transform()

3. è¨­å®šè³‡æ–™è¼¸å‡º
   data/{category}/

4. è¨­å®šæ’ç¨‹
   .github/workflows/scrape-{event}.yml

5. å‰ç«¯è¨­å®š
   data/categories.json

6. æ¸¬è©¦æ•´åˆ
   æ‰‹å‹•åŸ·è¡Œ + é©—è­‰è¼¸å‡º
```

---

## å‰ç½®éœ€æ±‚

### ä½ éœ€è¦æº–å‚™

1. **ç›®æ¨™è³½äº‹ç¶²ç«™**
   - ç¶²å€ï¼ˆä¾‹å¦‚ï¼šhttps://www.fiba.basketball/competitionsï¼‰
   - ç¶²ç«™çµæ§‹ï¼ˆéœæ…‹ HTML æˆ–éœ€è¦ JavaScript æ¸²æŸ“ï¼‰
   - è³‡æ–™æ ¼å¼ï¼ˆHTMLã€JSONã€XML ç­‰ï¼‰

2. **è³½äº‹åˆ†é¡è³‡è¨Š**
   - é‹å‹•ç¨®é¡ï¼ˆä¾‹å¦‚ï¼šbasketballã€footballï¼‰
   - è³½äº‹ç´šåˆ¥ï¼ˆä¾‹å¦‚ï¼šinternationalã€professionalï¼‰
   - æ™‚å€è³‡è¨Š

3. **é–‹ç™¼ç’°å¢ƒ**
   - å·²å®Œæˆéšæ®µ 1ï¼ˆ`scraper-core`ã€`json-manager`ã€`ics-generator`ï¼‰
   - æ¸¬è©¦ç’°å¢ƒå¯æ­£å¸¸é‹ä½œ

---

## å®Œæ•´æµç¨‹

### Step 1ï¼šå»ºç«‹æ–° Scraper Package

#### 1.1 è¤‡è£½ç¯„æœ¬

```bash
# å¾ scraper-bwf è¤‡è£½çµæ§‹
cp -r packages/scraper-bwf packages/scraper-{event-name}
cd packages/scraper-{event-name}
```

#### 1.2 ä¿®æ”¹ package.json

```json
{
  "name": "@matchcal/scraper-{event-name}",
  "version": "0.1.0",
  "description": "{Event Name} event scraper",
  "main": "src/index.js",
  "scripts": {
    "test": "vitest run",
    "test:watch": "vitest",
    "scrape": "node src/cli.js"
  },
  "dependencies": {
    "@matchcal/scraper-core": "workspace:*",
    "@matchcal/json-manager": "workspace:*",
    "@matchcal/ics-generator": "workspace:*",
    "puppeteer": "^23.0.0"
  },
  "devDependencies": {
    "vitest": "^2.0.0"
  }
}
```

#### 1.3 å»ºç«‹ç›®éŒ„çµæ§‹

```
packages/scraper-{event-name}/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js         # ä¸»è¦è¼¸å‡º
â”‚   â”œâ”€â”€ scraper.js       # çˆ¬èŸ²å¯¦ä½œ
â”‚   â”œâ”€â”€ transformer.js   # è³‡æ–™è½‰æ›
â”‚   â””â”€â”€ cli.js           # CLI åŸ·è¡Œæª”
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ scraper.test.js
â”‚   â””â”€â”€ transformer.test.js
â”œâ”€â”€ package.json
â””â”€â”€ SPEC.md
```

---

### Step 2ï¼šå¯¦ä½œ Scraperï¼ˆéµå¾ª TDDï¼‰

#### 2.1 æ’°å¯« SPEC.md

å…ˆå®šç¾©é€™å€‹ scraper çš„è¦æ ¼ï¼š

```markdown
# Scraper {Event Name} è¦æ ¼

## è·è²¬
çˆ¬å– {Event Name} å®˜æ–¹ç¶²ç«™çš„è³½äº‹è³‡è¨Š

## è³‡æ–™ä¾†æº
- URL: https://example.com/events
- æ ¼å¼: HTMLï¼ˆæˆ– JSON/XMLï¼‰
- æ›´æ–°é »ç‡: æ¯å¤©

## è¼¸å‡º
- JSON: /data/{category}/{source}-2025.json
- ICS: /data/{category}/{source}-2025.ics

## API

### EventScraper.scrape()
çˆ¬å–ä¸¦è¿”å› StandardEvent é™£åˆ—

### EventTransformer.transform(rawData)
è½‰æ›åŸå§‹è³‡æ–™ç‚º StandardEvent
```

#### 2.2 ğŸ”´ REDï¼šå¯«å¤±æ•—æ¸¬è©¦

```javascript
// tests/scraper.test.js
import { describe, it, expect } from 'vitest';
import { EventScraper } from '../src/scraper.js';

describe('EventScraper', () => {
  it('should scrape events and return array', async () => {
    const scraper = new EventScraper();
    const events = await scraper.scrape();

    expect(Array.isArray(events)).toBe(true);
  });

  it('should return events with standard schema', async () => {
    const scraper = new EventScraper();
    const events = await scraper.scrape();

    const firstEvent = events[0];
    expect(firstEvent).toHaveProperty('id');
    expect(firstEvent).toHaveProperty('title');
    expect(firstEvent).toHaveProperty('startDate');
    expect(firstEvent).toHaveProperty('endDate');
    expect(firstEvent).toHaveProperty('category');
  });
});
```

åŸ·è¡Œ `pnpm test` â†’ âŒ å¤±æ•—

#### 2.3 ğŸŸ¢ GREENï¼šå¯¦ä½œ Scraper

```javascript
// src/scraper.js
import { BaseScraper } from '@matchcal/scraper-core';
import { EventTransformer } from './transformer.js';
import puppeteer from 'puppeteer';

export class EventScraper extends BaseScraper {
  constructor() {
    super({
      source: '{source-name}',
      category: '{category}',
      url: 'https://example.com/events'
    });
    this.transformer = new EventTransformer();
  }

  async scrape() {
    const browser = await puppeteer.launch({ headless: true });
    const page = await browser.newPage();

    try {
      await page.goto(this.url, { waitUntil: 'networkidle2' });

      // çˆ¬å–è³‡æ–™
      const rawData = await page.evaluate(() => {
        // å¯¦ä½œçˆ¬å–é‚è¼¯
        // è¿”å›åŸå§‹è³‡æ–™é™£åˆ—
        return [];
      });

      await browser.close();

      // è½‰æ›ç‚º StandardEvent æ ¼å¼
      return rawData.map(item => this.transformer.transform(item));
    } catch (error) {
      await browser.close();
      throw error;
    }
  }
}
```

```javascript
// src/transformer.js
import { generateEventId } from '@matchcal/scraper-core';

export class EventTransformer {
  transform(rawData) {
    // å¯¦ä½œè½‰æ›é‚è¼¯
    const event = {
      title: rawData.name,
      startDate: new Date(rawData.start).toISOString(),
      endDate: new Date(rawData.end).toISOString(),
      timezone: 'Asia/Taipei',
      location: rawData.location,
      category: 'basketball',
      level: 'international',
      source: 'fiba',
      createdAt: new Date().toISOString(),
      updatedAt: new Date().toISOString(),
      scrapedAt: new Date().toISOString(),
    };

    // ç”Ÿæˆ ID
    event.id = generateEventId(event);

    return event;
  }
}
```

åŸ·è¡Œ `pnpm test` â†’ âœ… é€šé

#### 2.4 ğŸ”µ REFACTORï¼šæ”¹å–„ç¨‹å¼ç¢¼

- æå–é‡è¤‡é‚è¼¯
- æ”¹å–„å‘½å
- åŠ å…¥éŒ¯èª¤è™•ç†

---

### Step 3ï¼šè¨­å®šè³‡æ–™è¼¸å‡º

#### 3.1 å»ºç«‹è³‡æ–™ç›®éŒ„

```bash
mkdir -p data/{category}
```

ä¾‹å¦‚ï¼š
```bash
mkdir -p data/basketball
```

#### 3.2 å»ºç«‹ CLI åŸ·è¡Œæª”

```javascript
// src/cli.js
import { EventScraper } from './scraper.js';
import { JsonManager } from '@matchcal/json-manager';
import { IcsGenerator } from '@matchcal/ics-generator';
import path from 'path';

async function main() {
  try {
    console.log('Starting scraper...');

    // çˆ¬å–è³‡æ–™
    const scraper = new EventScraper();
    const events = await scraper.scrape();

    console.log(`Scraped ${events.length} events`);

    // è¼¸å‡ºè·¯å¾‘
    const dataDir = path.resolve(process.cwd(), '../../data/{category}');
    const jsonPath = path.join(dataDir, '{source}-2025.json');
    const icsPath = path.join(dataDir, '{source}-2025.ics');

    // å„²å­˜ JSON
    const jsonManager = new JsonManager();
    await jsonManager.write(jsonPath, events);
    console.log(`JSON saved to ${jsonPath}`);

    // ç”Ÿæˆ ICS
    const icsGenerator = new IcsGenerator();
    await icsGenerator.generate(icsPath, events);
    console.log(`ICS saved to ${icsPath}`);

    console.log('âœ… Scraping completed successfully');
  } catch (error) {
    console.error('âŒ Scraping failed:', error);
    process.exit(1);
  }
}

main();
```

#### 3.3 æ¸¬è©¦æ‰‹å‹•åŸ·è¡Œ

```bash
pnpm --filter @matchcal/scraper-{event} scrape
```

é©—è­‰ï¼š
- `/data/{category}/{source}-2025.json` å·²ç”Ÿæˆ
- `/data/{category}/{source}-2025.ics` å·²ç”Ÿæˆ

---

### Step 4ï¼šè¨­å®š GitHub Actions æ’ç¨‹

#### 4.1 å»ºç«‹ workflow æª”æ¡ˆ

```yaml
# .github/workflows/scrape-{event}.yml
name: Scrape {Event Name} Events

on:
  schedule:
    # æ¯å¤© UTC 00:00 åŸ·è¡Œ
    - cron: '0 0 * * *'
  workflow_dispatch:  # å…è¨±æ‰‹å‹•è§¸ç™¼

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install

      - name: Run scraper
        run: pnpm --filter @matchcal/scraper-{event} scrape

      - name: Commit and push changes
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add data/
          git commit -m "chore: update {event-name} events data [skip ci]" || exit 0
          git push
```

#### 4.2 æ¸¬è©¦æ‰‹å‹•è§¸ç™¼

åœ¨ GitHub Actions é é¢é»æ“Šã€ŒRun workflowã€æ¸¬è©¦ã€‚

---

### Step 5ï¼šå‰ç«¯è¨­å®š

#### 5.1 æ›´æ–° categories.json

```json
{
  "categories": [
    {
      "id": "basketball",
      "name": "ç±ƒçƒ",
      "nameEn": "Basketball",
      "icon": "ğŸ€",
      "color": "#F59E0B",
      "description": "åœ‹éš›ç±ƒçƒè³½äº‹",
      "sources": [
        {
          "id": "fiba",
          "name": "FIBA å®˜æ–¹è³½ç¨‹",
          "dataFile": "/data/basketball/fiba-2025.json",
          "icsFile": "/data/basketball/fiba-2025.ics"
        }
      ]
    }
  ]
}
```

#### 5.2 æ¸¬è©¦å‰ç«¯é¡¯ç¤º

```bash
pnpm --filter @matchcal/web dev
```

è¨ªå• http://localhost:3000ï¼Œç¢ºèªæ–°åˆ†é¡é¡¯ç¤ºæ­£ç¢ºã€‚

---

### Step 6ï¼šæ•´åˆæ¸¬è©¦

#### 6.1 æ¸¬è©¦æª¢æŸ¥æ¸…å–®

ä½¿ç”¨ä¸‹æ–¹çš„[æ¸¬è©¦æª¢æŸ¥æ¸…å–®](#æ¸¬è©¦æª¢æŸ¥æ¸…å–®)é€é …é©—è­‰ã€‚

#### 6.2 å¯«æ•´åˆæ¸¬è©¦ï¼ˆå¯é¸ï¼‰

```javascript
// tests/integration.test.js
import { describe, it, expect } from 'vitest';
import { EventScraper } from '../src/scraper.js';
import { validateEvents } from '@matchcal/scraper-core';
import fs from 'fs/promises';

describe('Integration Test', () => {
  it('should scrape, transform, and save data', async () => {
    // Scrape
    const scraper = new EventScraper();
    const events = await scraper.scrape();

    // Validate
    expect(events.length).toBeGreaterThan(0);
    expect(() => validateEvents(events)).not.toThrow();

    // Check JSON file exists
    const jsonExists = await fs.access('../../data/{category}/{source}-2025.json')
      .then(() => true)
      .catch(() => false);
    expect(jsonExists).toBe(true);

    // Check ICS file exists
    const icsExists = await fs.access('../../data/{category}/{source}-2025.ics')
      .then(() => true)
      .catch(() => false);
    expect(icsExists).toBe(true);
  });
});
```

---

## æ¸¬è©¦æª¢æŸ¥æ¸…å–®

### âœ… Scraper åŠŸèƒ½æ¸¬è©¦

- [ ] **Scraper å–®å…ƒæ¸¬è©¦é€šé**
  ```bash
  pnpm --filter @matchcal/scraper-{event} test
  ```

- [ ] **è³‡æ–™ç¬¦åˆ StandardEvent Schema**
  - [ ] æ‰€æœ‰å¿…è¦æ¬„ä½å­˜åœ¨ï¼ˆid, title, startDate, endDate, timezone, location, category, level, sourceï¼‰
  - [ ] æ—¥æœŸæ ¼å¼æ­£ç¢ºï¼ˆISO 8601ï¼‰
  - [ ] timezone ç‚ºæœ‰æ•ˆçš„ IANA timezone
  - [ ] id æ ¼å¼æ­£ç¢ºï¼ˆ`{category}-{source}-{date}-{slug}`ï¼‰

- [ ] **æ‰‹å‹•åŸ·è¡Œçˆ¬èŸ²æˆåŠŸ**
  ```bash
  pnpm --filter @matchcal/scraper-{event} scrape
  ```

### âœ… è³‡æ–™è¼¸å‡ºæ¸¬è©¦

- [ ] **JSON æª”æ¡ˆæ­£ç¢ºç”Ÿæˆ**
  - [ ] æª”æ¡ˆå­˜åœ¨æ–¼ `/data/{category}/{source}-2025.json`
  - [ ] æª”æ¡ˆåŒ…å« `meta` èˆ‡ `events` æ¬„ä½
  - [ ] `meta.eventCount` æ­£ç¢º
  - [ ] æ‰€æœ‰ events ç¬¦åˆ StandardEvent æ ¼å¼

- [ ] **ICS æª”æ¡ˆæ­£ç¢ºç”Ÿæˆ**
  - [ ] æª”æ¡ˆå­˜åœ¨æ–¼ `/data/{category}/{source}-2025.ics`
  - [ ] æª”æ¡ˆç¬¦åˆ RFC 5545 è¦ç¯„
  - [ ] åŒ…å« `BEGIN:VCALENDAR` å’Œ `END:VCALENDAR`
  - [ ] æ¯å€‹è³½äº‹æœ‰å°æ‡‰çš„ `VEVENT`

- [ ] **ICS æª”æ¡ˆå¯è¢«è¡Œäº‹æ›†è»Ÿé«”è®€å–**
  - [ ] Google Calendar å¯åŒ¯å…¥
  - [ ] Apple Calendar å¯åŒ¯å…¥
  - [ ] Outlook å¯åŒ¯å…¥

### âœ… å‰ç«¯æ•´åˆæ¸¬è©¦

- [ ] **åˆ†é¡é¡¯ç¤ºæ­£ç¢º**
  - [ ] æ–°åˆ†é¡å‡ºç¾åœ¨é¦–é 
  - [ ] åˆ†é¡åœ–ç¤ºèˆ‡é¡è‰²æ­£ç¢º
  - [ ] åˆ†é¡åç¨±æ­£ç¢ºï¼ˆä¸­è‹±æ–‡ï¼‰

- [ ] **è³½äº‹åˆ—è¡¨é¡¯ç¤ºæ­£ç¢º**
  - [ ] é»æ“Šåˆ†é¡å¾Œé¡¯ç¤ºè³½äº‹åˆ—è¡¨
  - [ ] è³½äº‹è³‡è¨Šå®Œæ•´ï¼ˆæ¨™é¡Œã€æ™‚é–“ã€åœ°é»ï¼‰
  - [ ] æ™‚é–“æ ¼å¼æ­£ç¢ºï¼ˆæœ¬åœ°åŒ–é¡¯ç¤ºï¼‰

- [ ] **è¨‚é–±åŠŸèƒ½æ­£å¸¸**
  - [ ] å¯ä¸‹è¼‰ ICS æª”æ¡ˆ
  - [ ] è¨‚é–±é€£çµæ­£ç¢ºï¼ˆWebcalï¼‰
  - [ ] è¨‚é–±å¾Œè¡Œäº‹æ›†è‡ªå‹•åŒæ­¥

### âœ… GitHub Actions æ¸¬è©¦

- [ ] **æ’ç¨‹ä»»å‹™æ­£å¸¸åŸ·è¡Œ**
  - [ ] æ‰‹å‹•è§¸ç™¼ workflow æˆåŠŸ
  - [ ] è³‡æ–™è‡ªå‹•æ›´æ–°
  - [ ] è‡ªå‹• commit ä¸¦ push

- [ ] **éŒ¯èª¤è™•ç†æ­£å¸¸é‹ä½œ**
  - [ ] çˆ¬èŸ²å¤±æ•—æ™‚æœ‰éŒ¯èª¤è¨Šæ¯
  - [ ] å¤±æ•—æ™‚ä¸ commit éŒ¯èª¤è³‡æ–™
  - [ ] GitHub Actions logs å¯æŸ¥çœ‹éŒ¯èª¤

### âœ… ç¨‹å¼ç¢¼å“è³ªæ¸¬è©¦

- [ ] **æ‰€æœ‰æ¸¬è©¦é€šé**
  ```bash
  pnpm test
  ```

- [ ] **Linter æª¢æŸ¥é€šé**
  ```bash
  pnpm lint
  ```

- [ ] **æ¸¬è©¦è¦†è“‹ç‡é”æ¨™**ï¼ˆç›®æ¨™ 80%+ï¼‰
  ```bash
  pnpm test:coverage
  ```

---

## ç¯„ä¾‹ï¼šæ–°å¢ç±ƒçƒè³½äº‹

### å ´æ™¯

æ–°å¢ FIBA ç±ƒçƒè³½äº‹ä¾†æºï¼šhttps://www.fiba.basketball/competitions

### Step 1ï¼šå»ºç«‹ Package

```bash
cp -r packages/scraper-bwf packages/scraper-fiba
cd packages/scraper-fiba
```

### Step 2ï¼šä¿®æ”¹ package.json

```json
{
  "name": "@matchcal/scraper-fiba",
  "description": "FIBA basketball event scraper"
}
```

### Step 3ï¼šå¯¦ä½œ Scraper

```javascript
// src/scraper.js
export class FibaScraper extends BaseScraper {
  constructor() {
    super({
      source: 'fiba',
      category: 'basketball',
      url: 'https://www.fiba.basketball/competitions'
    });
  }

  async scrape() {
    // å¯¦ä½œçˆ¬å–é‚è¼¯
  }
}
```

### Step 4ï¼šå»ºç«‹è³‡æ–™ç›®éŒ„

```bash
mkdir -p data/basketball
```

### Step 5ï¼šè¨­å®šæ’ç¨‹

```yaml
# .github/workflows/scrape-fiba.yml
name: Scrape FIBA Events
on:
  schedule:
    - cron: '0 0 * * *'
```

### Step 6ï¼šæ›´æ–°åˆ†é¡

```json
{
  "categories": [
    {
      "id": "basketball",
      "name": "ç±ƒçƒ",
      "icon": "ğŸ€",
      "sources": [
        {
          "id": "fiba",
          "name": "FIBA å®˜æ–¹è³½ç¨‹",
          "dataFile": "/data/basketball/fiba-2025.json",
          "icsFile": "/data/basketball/fiba-2025.ics"
        }
      ]
    }
  ]
}
```

### Step 7ï¼šæ¸¬è©¦

```bash
# åŸ·è¡Œçˆ¬èŸ²
pnpm --filter @matchcal/scraper-fiba scrape

# æª¢æŸ¥è¼¸å‡º
ls data/basketball/

# å•Ÿå‹•å‰ç«¯
pnpm --filter @matchcal/web dev
```

âœ… å®Œæˆï¼

---

## å¸¸è¦‹å•é¡Œ

### Q: éœ€è¦ä¿®æ”¹ scraper-core å—ï¼Ÿ

A: **ä¸éœ€è¦**ã€‚`scraper-core` æ˜¯é€šç”¨æ¡†æ¶ï¼Œæ–°å¢è³½äº‹åªéœ€ç¹¼æ‰¿ `BaseScraper`ã€‚

### Q: å¦‚ä½•è™•ç†éœ€è¦ç™»å…¥çš„ç¶²ç«™ï¼Ÿ

A: åœ¨ scraper ä¸­ä½¿ç”¨ Puppeteer è™•ç†ç™»å…¥æµç¨‹ï¼Œæˆ–ä½¿ç”¨ç’°å¢ƒè®Šæ•¸å„²å­˜æ†‘è­‰ã€‚

### Q: å¦‚ä½•è™•ç†åˆ†é è³‡æ–™ï¼Ÿ

A: åœ¨ `scrape()` æ–¹æ³•ä¸­å¯¦ä½œåˆ†é é‚è¼¯ï¼š

```javascript
async scrape() {
  const allEvents = [];
  let page = 1;

  while (true) {
    const events = await this.scrapePage(page);
    if (events.length === 0) break;

    allEvents.push(...events);
    page++;
  }

  return allEvents;
}
```

### Q: å¦‚ä½•æ¸¬è©¦çˆ¬èŸ²ä¸æœƒè¢«å°é–ï¼Ÿ

A:
- è¨­å®šåˆç†çš„ delay
- ä½¿ç”¨éš¨æ©Ÿ User-Agent
- éµå®ˆ robots.txt
- é¿å…éåº¦è«‹æ±‚

### Q: è‡ªè¨‚æ¬„ä½æœƒè¢«è¦†è“‹å—ï¼Ÿ

A: **ä¸æœƒ**ã€‚`json-manager` æœƒä¿ç•™ `customFields` ä¸­çš„æ‰€æœ‰æ‰‹å‹•æ–°å¢æ¬„ä½ã€‚

### Q: å¯ä»¥åŒæ™‚æ”¯æ´å¤šå€‹è³‡æ–™ä¾†æºå—ï¼Ÿ

A: å¯ä»¥ã€‚åœ¨åŒä¸€å€‹ category ä¸‹å»ºç«‹å¤šå€‹ scraper packagesï¼Œä¾‹å¦‚ï¼š
- `packages/scraper-fiba`ï¼ˆFIBA å®˜æ–¹ï¼‰
- `packages/scraper-nba`ï¼ˆNBA å®˜æ–¹ï¼‰

å…©è€…éƒ½è¼¸å‡ºåˆ° `data/basketball/`ï¼Œå‰ç«¯æœƒåˆä½µé¡¯ç¤ºã€‚

---

## ğŸ“š ç›¸é—œæ–‡ä»¶

- [è³‡æ–™æ ¼å¼è¦ç¯„](../technical/DATA-SCHEMA.md)
- [çˆ¬èŸ²ä»‹é¢](../technical/SCRAPER-INTERFACE.md)
- [TDD å·¥ä½œæµç¨‹](TDD-WORKFLOW.md)
- [ç³»çµ±æ¶æ§‹](../ARCHITECTURE.md)

---

ğŸ¯ **è¼•é¬†æ–°å¢è³½äº‹ä¾†æºï¼Œæ“´å……å°ˆæ¡ˆåŠŸèƒ½ï¼**
